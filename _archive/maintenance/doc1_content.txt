HomeDocManager の Go / Rust リファクタリングによる
パフォーマンス最適化・コスト削減 評価レポート

対象: Python 実装の HomeDocManager（Cloud Run デプロイ）
目的: Cloud Run 無料枠を意識したコスト削減（第一優先）と、保守性（ロギング・デバッグ容易性）の向上

1. 結論（サマリ）
結論として、Go もしくは Rust への（部分的または全面的な）リファクタリングで、Cloud Run 上のコスト削減と運用品質向上は十分に狙えます。
特に、(1) コールドスタート短縮、(2) アイドル時のメモリ常駐量の削減、(3) 高並行（I/O と API 呼び出し）処理の効率化、(4) OCR 周辺の CPU 負荷の最適化が主な改善ポイントです。
推奨は「まず Go でサービス全体（または OCR オーケストレーション）を置き換え、必要なら Rust をホットパス（画像/PDF前処理など）に限定して導入する」段階的アプローチです。
2. 前提とスコープ
・実行環境: GCP Cloud Run（スケール to 0 を前提。無料枠内にできるだけ収めたい）
・OCR: Gemini API 利用可（OCR 自体はクラウド側で計算。クライアント側は画像前処理・転送・結果処理が主）
・現状: ある程度満足できる性能。ただし将来の保守（ロギング、デバッグ、可観測性）も改善したい
・優先度: コスト削減 ＞（同等以上の）スループット ＞ 保守性
3. どこで効くか（改善余地が大きい箇所）
3.1 OCR パイプライン（画像/PDF前処理 → API 呼び出し → 結果整形）
・画像のリサイズ/回転補正/二値化などの前処理がある場合、Go/Rust の方が CPU 効率が良く、処理時間短縮＝課金 CPU 秒の削減につながりやすい。
・Gemini API の呼び出し自体はネットワーク待ちが中心。Go の goroutine や Rust の async により、待ち時間を隠蔽しながら複数リクエスト/複数ページを効率よく並列化できる。
・ストリーミング転送（ファイルを丸ごとメモリに載せない）を徹底すると、メモリ使用量を抑えやすい。
3.2 Cloud Run の「スケール to 0」とコールドスタート
・Python は起動時にインタプリタと多数のモジュールをロードしがちで、コールドスタートが長くなりやすい。
・Go/Rust は単一バイナリ中心のため起動が速く、スケール to 0 をより積極的に活用しやすい。結果として、常時稼働（min instances）を避けられ、アイドル課金を抑えやすい。
3.3 高並行 I/O（アップロード、ストレージ、外部 API、DB など）
・Cloud Run は 1 インスタンスで複数同時リクエストを捌けるが、Python は GIL や実行モデル次第で効率が落ちる場合がある。
・Go/Rust は並行処理を言語レベルで扱いやすく、少ないリソースで同時処理を増やしやすい。インスタンス数が増えにくくなるため、コスト削減に直結することが多い。
4. 期待できる効果（Cloud Run 観点）
※ 以下は一般的な傾向です。実測で最終判断することを推奨します（後述の計測計画参照）。
5. 推奨アーキテクチャ（段階的移行プラン）
5.1 最小リスクで効く順（おすすめ）
1) まず「計測」を整備（現状の CPU 秒、メモリ、レイテンシ、外部 API コール回数・サイズを可視化）
2) OCR 呼び出し周辺の I/O・並行処理を最適化（Go で置き換え推奨）
3) 画像/PDF 前処理が重い場合のみ、ホットパスを Rust に切り出し（Rust CLI またはライブラリ）
4) 効果が大きいと判断できたら、サービス全体を Go/Rust に統合（運用を単純化）
5.2 Go 単独 vs Go+Rust
・Go 単独: 開発コストと運用性のバランスが良い。Cloud Run との相性も良く、まずはこれで十分なことが多い。
・Go+Rust: 画像/圧縮/パースなど CPU ホットパスが明確で、そこだけ極限まで削りたい場合に有効。ただしビルド・CI/CD・デバッグが複雑になりやすいので、段階導入が安全。
6. コスト削減の具体的なレバー（Cloud Run）
・スケール to 0 を前提に、コールドスタート短縮で「常時稼働を避ける」
・メモリ割当を下げられるなら下げる（無料枠の消費を抑え、課金も減る）
・CPU ブースト/CPU 常時割当の設定を見直す（アイドル時課金の最小化）
・Cloud Run concurrency を適切に上げ、1 インスタンス当たりの処理密度を上げる（ただし OCR 処理の性質に合わせる）
・外部 API（Gemini）への送信データ量を削る（適切な圧縮/リサイズ）
・不要な再 OCR を避ける（ハッシュで重複排除、結果キャッシュ、失敗時リトライ方針の最適化）
7. 保守性（ロギング・デバッグ・可観測性）改善ポイント
・構造化ログ（JSON）を標準化し、リクエストID/ドキュメントID/ページ番号/外部 API のレイテンシを必須項目にする。
・分散トレーシング（OpenTelemetry）で「アップロード → 前処理 → Gemini 呼び出し → 後処理」のスパンを切り、ボトルネックを常に見える化。
・失敗時の再現性のため、入力サンプル（許容範囲で）とパラメータを安全に保存/再実行できる仕組みを用意。
・Cloud Run / Cloud Logging / Cloud Trace のダッシュボードを最初に整備（運用の負担が下がる）。
8. 実測で判断するための計測計画（おすすめ）
A. 現状（Python）で計測すべき項目
・1 リクエスト当たりの CPU 時間（推定）、メモリピーク、レスポンス時間（P50/P95）
・Gemini API: 呼び出し回数、送信サイズ、応答時間、失敗率
・Cloud Run: インスタンス数の推移、スケールアウト頻度、コールドスタート発生率
B. PoC（Go または Rust）で比較する
・同一入力（代表的な PDF/画像）で、CPU・メモリ・レイテンシを比較
・同時リクエスト（例: 1, 5, 10）でのスループットとコストを比較
・最もコストに効く設定（メモリ/CPU/Concurrency）を探索
9. まとめ（意思決定の指針）
・「無料枠に収めたい」「アイドル時コストを削りたい」なら、Go/Rust は有効な選択肢。特にコールドスタートとメモリ常駐の差が効きやすい。
・最短で成果を出すなら Go を第一候補にし、CPU ホットパスが明確なら Rust を部分導入。
・現状性能に大きな不満がない場合でも、計測→小さな PoC→段階移行で、リスクを抑えつつ ROI を最大化できる。
観点 | Python（現状） | Go（想定） | Rust（想定）
コールドスタート | 数秒になりがち（依存/初期化が重いと悪化） | 短い（単一バイナリで起動が速い） | 非常に短い（単一バイナリ、ランタイムが小さい）
アイドル時メモリ | インタプリタ常駐で相対的に大きめ | 小さく抑えやすい | 小さく抑えやすい（ただし実装次第）
並行処理 | I/O は async で改善可。CPU は工夫が必要 | goroutine で高効率。実装しやすい | async/スレッドで高効率。安全性が高い
開発・保守 | 開発速度は速いが、型/実行時バグや運用可観測性は設計次第 | 学習コスト低め。読みやすく運用向き | 学習コスト高め。安全性・信頼性は非常に高い
